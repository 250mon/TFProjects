{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795073a6-8d84-447f-9e5b-64a63409f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 00:48:28.112061: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c492222-088c-418e-9fd0-a97996f98263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 00:48:35.578909: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-14 00:48:35.601888: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-14 00:48:35.601996: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa82e5-8b71-4eae-a26b-d5445cdabf4b",
   "metadata": {},
   "source": [
    "## In mamory data\n",
    "For any small CSV dataset the simplest way to train a TensorFlow model on it is to load it into memory as a pandas DataFrame or a NumPy array.\n",
    "\n",
    "A relatively simple example is the abalone dataset.\n",
    "\n",
    "* The dataset is small.\n",
    "* All the input features are limited-range floating point values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "708f8585-aa15-47fe-a05a-a8b50ab0b0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf3d369-91da-4f61-aa16-b35422259b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b27f1f16-8d03-486b-8409-3e306c5cd331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.435, 0.335, 0.11 , ..., 0.136, 0.077, 0.097],\n",
       "       [0.585, 0.45 , 0.125, ..., 0.354, 0.207, 0.225],\n",
       "       [0.655, 0.51 , 0.16 , ..., 0.396, 0.282, 0.37 ],\n",
       "       ...,\n",
       "       [0.53 , 0.42 , 0.13 , ..., 0.374, 0.167, 0.249],\n",
       "       [0.395, 0.315, 0.105, ..., 0.118, 0.091, 0.119],\n",
       "       [0.45 , 0.355, 0.12 , ..., 0.115, 0.067, 0.16 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_features = np.array(abalone_features)\n",
    "abalone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "985fd133-dc25-4b66-8fe9-37f251eb4b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 00:49:00.455091: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-14 00:49:00.455495: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-14 00:49:00.455776: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-14 00:49:00.515371: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-14 00:49:00.515470: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-14 00:49:00.515548: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-14 00:49:00.515883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22268 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9fc531-c155-4ad9-a35a-60ab889d6b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713055744.012428     187 service.cc:145] XLA service 0x795ed4013f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1713055744.012447     187 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-14 00:49:04.029935: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-14 00:49:04.086984: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 94.0638 \n",
      "Epoch 2/10\n",
      "\u001b[1m  1/104\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 59.9211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713055744.235807     187 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 38.2300\n",
      "Epoch 3/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 10.1926\n",
      "Epoch 4/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - loss: 9.2225\n",
      "Epoch 5/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - loss: 8.3561\n",
      "Epoch 6/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - loss: 8.1524\n",
      "Epoch 7/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - loss: 7.9957\n",
      "Epoch 8/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - loss: 7.0788\n",
      "Epoch 9/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - loss: 6.8939\n",
      "Epoch 10/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - loss: 6.9390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x795fd22b0550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec8c32-b712-4bbd-ae8e-97996274adc8",
   "metadata": {},
   "source": [
    "## Basic preprocessing\n",
    "\n",
    "It's good practice to normalize the inputs to your model. The Keras preprocessing layers provide a convenient way to build this normalization into your model.\n",
    "\n",
    "The `tf.keras.layers.Normalization` layer precomputes the mean and variance of each column, and uses these to normalize the data.\n",
    "\n",
    "First, create the layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789706a8-f3df-43a1-ab0a-37e4e0621eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = layers.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12fb2d64-000b-434e-b33d-179e8fea1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt the normalization layer to your data\n",
    "normalize.adapt(abalone_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b0c8574-b3fa-4711-bfb1-e45781a459b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 97.6242   \n",
      "Epoch 2/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 45.6015\n",
      "Epoch 3/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 30.9855\n",
      "Epoch 4/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 20.8785\n",
      "Epoch 5/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - loss: 12.5171\n",
      "Epoch 6/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - loss: 7.6099\n",
      "Epoch 7/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 6.9523\n",
      "Epoch 8/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 6.0372\n",
      "Epoch 9/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - loss: 5.6547\n",
      "Epoch 10/10\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - loss: 5.8727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x795fd04bc890>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then use the normalization layer in the model\n",
    "norm_abalone_model = tf.keras.Sequential([\n",
    "  normalize,\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "norm_abalone_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                           optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "norm_abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3996aa13-dcd6-4ccf-bd32-717c98bbdb18",
   "metadata": {},
   "source": [
    "## Mixed data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fb14bdc-d21c-4040-a4dd-3b59e0af9dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2828103d-22a3-477a-9f98-af20a5fbfe55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c3cb3eb-eb15-4cb0-bfc3-b813f58535cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71715650-34f7-478d-a376-3fe6320f4016",
   "metadata": {},
   "source": [
    "### Symbolic tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee80921-dbbb-4385-93fb-a9d98852d64a",
   "metadata": {},
   "source": [
    "The functional API operates on \"symbolic\" tensors. Normal \"eager\" tensors have a value. In contrast these \"symbolic\" tensors do not. Instead they keep track of which operations are run on them, and build a representation of the calculation, that you can run later. Here's a quick example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2afc9e7-1a89-4a0c-935d-971517fef734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None,), dtype=float32, sparse=False, name=keras_tensor_9>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a symbolic input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "# Perform a calculation using the input\n",
    "result = 2*input + 1\n",
    "\n",
    "# the result doesn't have a value\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aff2278-fd2b-468e-9609-0b818754c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = tf.keras.Model(inputs=input, outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c19413-4f2c-4a40-80bb-29b4b3dbd1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n",
      "[5.]\n"
     ]
    }
   ],
   "source": [
    "print(calc(np.array([1])).numpy())\n",
    "print(calc(np.array([2])).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7e372-3dae-418c-bdd2-825987c1bb1c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34344438-8a22-491d-8190-02db66dd1156",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64dde1-0461-4068-b406-94754513b3c0",
   "metadata": {},
   "source": [
    "```python\n",
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')\n",
    "\n",
    "# make a dict of tensors using dtypes for each input column\n",
    "inputs = {}\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "\n",
    "# collect numeric inputs\n",
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)  # shape(None, 4) tensors\n",
    "\n",
    "preprocessed_inputs = [all_numeric_inputs]\n",
    "\n",
    "\n",
    "# collect categorical inputs\n",
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)  # ending up appending shape(None, 24) input tensors\n",
    "\n",
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)  # shape=(None, 28); num+cat\n",
    "titanic_preprocessing = tf.keras.Model(inputs=inputs, outputs=preprocessed_inputs_cat)\n",
    "\n",
    "\n",
    "# create a model\n",
    "def titanic_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "  return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)\n",
    "\n",
    "\n",
    "# run a model\n",
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}\n",
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc36987-6553-424d-9eda-5ffc3f29cd61",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bcbc2e-8f56-43ec-a041-b37e8a0482c5",
   "metadata": {},
   "source": [
    "### Collect numeric inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15e7dac6-af70-4225-9aa9-7ae0fc587776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': <KerasTensor shape=(None, 1), dtype=string, sparse=None, name=sex>,\n",
       " 'age': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=age>,\n",
       " 'n_siblings_spouses': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=n_siblings_spouses>,\n",
       " 'parch': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=parch>,\n",
       " 'fare': <KerasTensor shape=(None, 1), dtype=float32, sparse=None, name=fare>,\n",
       " 'class': <KerasTensor shape=(None, 1), dtype=string, sparse=None, name=class>,\n",
       " 'deck': <KerasTensor shape=(None, 1), dtype=string, sparse=None, name=deck>,\n",
       " 'embark_town': <KerasTensor shape=(None, 1), dtype=string, sparse=None, name=embark_town>,\n",
       " 'alone': <KerasTensor shape=(None, 1), dtype=string, sparse=None, name=alone>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097d5bc-15ed-4ad2-a393-9461d1909bbc",
   "metadata": {},
   "source": [
    "The first step in your preprocessing logic is to concatenate the numeric inputs together, and run them through a normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b89e0788-fd6c-4dc0-8f3a-f61627e0d2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 4), dtype=float32, sparse=False, name=keras_tensor_11>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05685a27-3fc4-452a-808b-5e668c5fa266",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c6892d-acc0-436f-832e-947bdbc0f581",
   "metadata": {},
   "source": [
    "### Collecting categorical inputs\n",
    "For the string inputs use the `tf.keras.layers.StringLookup` function to map from strings to integer indices in a vocabulary. Next, use `tf.keras.layers.CategoryEncoding` to convert the indexes into float32 data appropriate for the model.\n",
    "\n",
    "The default settings for the `tf.keras.layers.CategoryEncoding` layer create a one-hot vector for each input. A `tf.keras.layers.Embedding` would also work. Check out the Working with preprocessing layers guide and the Classify structured data using Keras preprocessing layers tutorial for more on this topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef503a6b-606b-4963-a5fc-6986828bc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76f4af3-6905-4d76-848d-422ee850cbe7",
   "metadata": {},
   "source": [
    "With the collection of `inputs` and `preprocessed_inputs`, you can concatenate all the preprocessed inputs together, and build a model that handles the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35d2fe-5fe5-4ce3-91df-6b8c94d5c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "titanic_preprocessing = tf.keras.Model(inputs=inputs, outputs=preprocessed_inputs_cat)\n",
    "\n",
    "#tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d828b252-2632-4b9d-973c-97c2e3a5d35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 28), dtype=float32, sparse=False, name=keras_tensor_22>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_inputs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09513802-392e-4264-a0bb-da826d94df4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['male', 'female', 'female'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}\n",
    "\n",
    "display(titanic_features_dict.keys())\n",
    "display(list(titanic_features_dict.values())[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6acfb4da-d157-422c-9341-f2f979160a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': array(['male'], dtype=object),\n",
       " 'age': array([22.]),\n",
       " 'n_siblings_spouses': array([1]),\n",
       " 'parch': array([0]),\n",
       " 'fare': array([7.25]),\n",
       " 'class': array(['Third'], dtype=object),\n",
       " 'deck': array(['unknown'], dtype=object),\n",
       " 'embark_town': array(['Southampton'], dtype=object),\n",
       " 'alone': array(['n'], dtype=object)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first element of slices\n",
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e60f3-4c00-4d60-81df-381af2186c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 28), dtype=float32, numpy=\n",
       "array([[-0.61 ,  0.395, -0.479, -0.497,  0.   ,  0.   ,  1.   ,  0.   ,\n",
       "         0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ,  0.   ,  1.   ,  0.   ]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c32bf6b9-af4d-42dd-a5b0-d7c1da7dfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam())\n",
    "  return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2cfc0ad-b104-48aa-b133-5a2946ad0a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6691   \n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6012 \n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5506 \n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5141 \n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4930 \n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4428 \n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4216 \n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4283 \n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4337 \n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3994 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x795fc5f41dd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6407c01-5ddb-49a8-bf61-37f10091c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_model.save('test.keras')\n",
    "reloaded = tf.keras.models.load_model('test.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1886552d-639d-4eee-a04c-4d0e27104f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_model.save('test.keras')\n",
    "reloaded = tf.keras.models.load_model('test.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3fc6167-397f-4a58-9a94-8824eb227983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-1.944]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[-1.944]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9237f9c-0b2f-4b08-a3e3-3afd3afe5a0f",
   "metadata": {},
   "source": [
    "## Using tf.data\n",
    "\n",
    "In the previous section you relied on the model's built-in data shuffling and batching while training the model.\n",
    "\n",
    "If you need more control over the input data pipeline or need to use data that doesn't easily fit into memory: use `tf.data`.\n",
    "\n",
    "For more examples, refer to the `tf.data`: Build TensorFlow input pipelines guide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e3de6-a42c-4544-bca6-59e3bb33cd88",
   "metadata": {},
   "source": [
    "### On in memory data\n",
    "\n",
    "As a first example of applying `tf.data` to CSV data, consider the following code to manually slice up the dictionary of features from the previous section. For each index, it takes that index for each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2fff34d-f0f2-4694-9a9f-94b2f19dbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def slices(features):\n",
    "    for i in itertools.count():\n",
    "        # For each feature take index `i`\n",
    "        example = {name: values[i] for name, values in features.items()}\n",
    "        yield example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10d1d87b-2676-4ce9-abcb-721b64b5ec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : male\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : Third\n",
      "deck               : unknown\n",
      "embark_town        : Southampton\n",
      "alone              : n\n"
     ]
    }
   ],
   "source": [
    "for example in slices(titanic_features_dict):\n",
    "    for name, value in example.items():\n",
    "        print(f\"{name:19s}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21591b16-0e58-4bb6-befe-f5c426f34c98",
   "metadata": {},
   "source": [
    "**`tf.data.Dataset.from_tensor_slices`**  \n",
    "\n",
    "The most basic `tf.data.Dataset` in memory data loader is the `Dataset.from_tensor_slices` constructor. This returns a `tf.data.Dataset` that implements a generalized version of the above `slices` function, in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f773960-c9f0-4e8d-9719-ac2bc4a0c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc145ae0-9230-4d03-afb0-54db7c79c445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : b'male'\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : b'Third'\n",
      "deck               : b'unknown'\n",
      "embark_town        : b'Southampton'\n",
      "alone              : b'n'\n"
     ]
    }
   ],
   "source": [
    "for example in features_ds:\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb1db1f-ce47-4454-9424-91ddf7203a85",
   "metadata": {},
   "source": [
    "The `from_tensor_slices` function can handle any structure of nested dictionaries or tuples. The following code makes a dataset of `(features_dict, labels)` pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1947900c-710a-481c-8088-87acf2715098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': array(['male', 'female', 'female', 'female', 'male', 'male', 'female',\n",
       "        'female', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "        'female', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "        'female', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "        'male', 'male', 'female', 'female', 'female', 'male', 'female',\n",
       "        'male', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "        'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "        'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "        'male', 'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "        'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "        'male', 'male', 'female', 'male', 'female', 'male', 'male', 'male',\n",
       "        'male', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "        'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "        'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "        'male', 'male', 'female', 'female', 'male', 'male', 'female',\n",
       "        'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "        'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "        'male', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "        'female', 'female', 'male', 'male', 'female', 'female', 'male',\n",
       "        'female', 'female', 'male', 'female', 'female', 'male', 'male',\n",
       "        'male', 'female', 'male', 'male', 'female', 'male', 'female',\n",
       "        'male', 'male', 'female', 'female', 'male', 'male', 'male', 'male',\n",
       "        'male', 'male', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "        'female', 'male', 'male', 'male', 'female', 'female', 'male',\n",
       "        'male', 'male', 'female', 'male', 'female', 'male', 'female',\n",
       "        'female', 'female', 'female', 'male', 'male', 'male', 'female',\n",
       "        'male', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "        'female', 'male', 'female', 'female', 'female', 'male', 'male',\n",
       "        'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "        'female', 'female', 'male', 'female', 'male', 'female', 'female',\n",
       "        'male', 'female', 'female', 'female', 'female', 'male', 'male',\n",
       "        'female', 'female', 'female', 'male', 'male', 'female', 'male',\n",
       "        'female', 'male', 'female', 'female', 'male', 'female', 'male',\n",
       "        'male', 'male', 'male', 'male', 'male', 'male', 'female', 'female',\n",
       "        'female', 'male', 'male', 'male', 'male', 'female', 'female',\n",
       "        'female', 'female', 'male', 'male', 'female', 'male', 'male',\n",
       "        'female', 'female', 'female', 'female', 'male', 'male', 'female',\n",
       "        'male', 'male', 'female', 'male', 'male', 'male', 'male', 'male',\n",
       "        'female', 'male', 'male', 'female', 'female', 'male', 'female',\n",
       "        'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "        'female', 'male', 'male', 'male', 'male', 'female', 'female',\n",
       "        'female', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "        'male', 'female', 'female', 'male', 'male', 'female', 'female',\n",
       "        'male', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "        'female', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "        'male', 'male', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "        'male', 'female', 'female', 'male', 'male', 'male', 'female',\n",
       "        'male', 'male', 'female', 'male', 'female', 'female', 'male',\n",
       "        'male', 'male', 'male', 'male', 'female', 'male', 'female',\n",
       "        'female', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "        'male', 'female', 'female', 'male', 'female', 'male', 'female',\n",
       "        'male', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "        'female', 'female', 'female', 'male', 'female', 'female', 'female',\n",
       "        'female', 'female', 'male', 'female', 'male', 'male', 'male',\n",
       "        'male', 'male', 'female', 'female', 'male', 'female', 'female',\n",
       "        'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "        'female', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "        'male', 'male', 'male', 'female', 'male', 'female', 'male', 'male',\n",
       "        'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "        'female', 'female', 'female', 'male', 'female', 'male', 'female',\n",
       "        'male', 'male', 'male', 'male', 'male', 'female', 'male', 'male',\n",
       "        'male', 'male', 'male', 'female', 'female', 'male', 'female',\n",
       "        'male', 'male', 'male', 'female', 'male', 'male', 'female', 'male',\n",
       "        'female', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "        'male', 'male', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "        'male', 'female', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "        'male', 'female', 'male', 'female', 'male', 'male', 'female',\n",
       "        'male', 'male', 'male', 'male', 'female', 'male', 'female', 'male',\n",
       "        'male', 'male', 'male', 'female', 'female', 'male', 'male',\n",
       "        'female', 'male', 'male', 'female', 'male', 'female', 'female',\n",
       "        'male', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "        'female', 'male', 'male', 'female', 'male', 'male', 'male',\n",
       "        'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "        'male', 'male', 'male', 'female', 'male', 'male', 'female',\n",
       "        'female', 'male', 'male', 'male', 'male', 'male', 'male', 'male',\n",
       "        'female', 'male', 'male', 'male', 'female', 'female', 'male',\n",
       "        'female', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "        'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "        'male', 'female', 'male', 'male', 'male', 'male', 'male', 'female',\n",
       "        'male', 'male', 'male', 'female', 'male', 'male', 'male', 'male',\n",
       "        'female', 'male', 'male', 'male', 'male', 'male', 'female', 'male',\n",
       "        'female', 'female', 'female', 'male', 'female', 'male', 'male',\n",
       "        'female', 'female', 'male', 'male', 'male', 'female', 'male',\n",
       "        'male', 'female', 'female', 'male', 'male', 'male', 'female',\n",
       "        'male', 'male', 'female', 'female', 'male'], dtype=object),\n",
       " 'age': array([22.  , 38.  , 26.  , 35.  , 28.  ,  2.  , 27.  , 14.  ,  4.  ,\n",
       "        20.  , 39.  , 14.  ,  2.  , 28.  , 31.  , 28.  , 35.  , 28.  ,\n",
       "        38.  , 28.  , 19.  , 28.  , 28.  , 40.  , 28.  , 28.  , 66.  ,\n",
       "        28.  , 42.  , 28.  , 14.  , 40.  , 27.  , 28.  ,  3.  , 28.  ,\n",
       "        28.  , 28.  , 18.  ,  7.  , 49.  , 29.  , 65.  , 28.  , 21.  ,\n",
       "        28.5 , 11.  , 22.  , 38.  , 45.  ,  4.  , 28.  , 19.  , 17.  ,\n",
       "        26.  , 32.  , 21.  , 32.  , 25.  , 28.  , 28.  ,  0.83, 30.  ,\n",
       "        22.  , 29.  , 28.  , 28.  , 16.  , 28.  , 23.  , 24.  , 46.  ,\n",
       "        59.  , 28.  , 71.  , 23.  , 34.  , 34.  , 28.  , 28.  , 21.  ,\n",
       "        33.  , 37.  , 28.  , 28.  , 28.  , 47.  , 14.5 , 22.  , 17.  ,\n",
       "        21.  , 70.5 , 29.  , 24.  , 28.  , 32.5 , 32.5 , 28.  , 24.  ,\n",
       "        45.  , 20.  , 47.  , 23.  , 19.  , 37.  , 16.  , 24.  , 28.  ,\n",
       "        22.  , 19.  , 18.  ,  9.  , 51.  , 55.5 , 40.5 , 28.  , 51.  ,\n",
       "        16.  , 28.  , 28.  , 44.  , 26.  , 17.  ,  1.  , 28.  , 28.  ,\n",
       "         4.  , 18.  , 28.  , 50.  , 30.  , 36.  , 28.  , 28.  ,  9.  ,\n",
       "         4.  , 28.  , 45.  , 36.  , 32.  , 19.  ,  3.  , 44.  , 58.  ,\n",
       "        28.  , 28.  , 24.  , 28.  , 28.  , 34.  ,  2.  , 32.  , 26.  ,\n",
       "        16.  , 40.  , 35.  , 22.  , 28.  , 31.  , 27.  , 42.  , 30.  ,\n",
       "        16.  , 51.  , 22.  , 19.  , 20.5 , 18.  , 28.  , 35.  , 29.  ,\n",
       "        59.  , 28.  , 44.  , 19.  , 33.  , 28.  , 28.  , 22.  , 30.  ,\n",
       "        44.  , 24.  , 28.  , 29.  , 30.  , 41.  , 28.  , 35.  , 50.  ,\n",
       "        28.  ,  3.  , 40.  , 28.  , 36.  , 16.  , 25.  , 58.  , 35.  ,\n",
       "        28.  , 25.  , 41.  , 37.  , 28.  , 63.  , 45.  , 28.  ,  7.  ,\n",
       "        35.  , 28.  , 16.  , 28.  , 26.  , 36.  , 24.  , 28.  , 50.  ,\n",
       "        28.  , 19.  , 28.  , 28.  , 28.  , 17.  , 30.  , 30.  , 24.  ,\n",
       "        18.  , 26.  , 28.  , 43.  , 24.  , 31.  , 40.  , 22.  , 27.  ,\n",
       "        22.  , 28.  , 36.  , 61.  , 31.  , 28.  , 38.  , 28.  , 28.  ,\n",
       "        29.  , 45.  , 45.  , 28.  , 25.  , 36.  , 24.  , 40.  , 28.  ,\n",
       "        15.  , 25.  , 28.  , 28.  , 22.  , 38.  , 28.  , 28.  , 40.  ,\n",
       "        29.  , 45.  , 35.  , 28.  , 60.  , 28.  , 28.  , 24.  , 18.  ,\n",
       "        19.  , 28.  , 27.  , 19.  , 42.  , 32.  , 28.  , 18.  ,  1.  ,\n",
       "        28.  , 17.  , 36.  , 21.  , 23.  , 24.  , 22.  , 31.  , 46.  ,\n",
       "        23.  , 39.  , 26.  , 28.  , 34.  ,  3.  , 21.  , 28.  , 28.  ,\n",
       "        28.  , 28.  , 44.  , 28.  , 34.  , 18.  , 30.  , 28.  , 21.  ,\n",
       "        18.  , 19.  , 28.  , 32.  , 28.  , 28.  , 42.  , 17.  , 50.  ,\n",
       "        14.  , 24.  , 64.  , 31.  , 45.  , 20.  , 28.  , 28.  , 34.  ,\n",
       "         5.  , 52.  , 36.  , 30.  , 49.  , 29.  , 65.  , 28.  , 48.  ,\n",
       "        34.  , 47.  , 28.  , 38.  , 56.  , 28.  ,  0.75, 28.  , 33.  ,\n",
       "        23.  , 28.  , 34.  , 29.  ,  2.  ,  9.  , 28.  , 63.  , 25.  ,\n",
       "        28.  , 35.  , 58.  ,  9.  , 28.  , 71.  , 21.  , 25.  , 17.  ,\n",
       "        21.  , 37.  , 18.  , 33.  , 28.  , 26.  , 54.  , 24.  , 47.  ,\n",
       "        34.  , 36.  , 32.  , 30.  , 22.  , 44.  , 28.  , 40.5 , 50.  ,\n",
       "        28.  , 23.  ,  2.  , 17.  , 28.  , 30.  ,  7.  , 45.  , 30.  ,\n",
       "        22.  , 36.  ,  9.  , 11.  , 50.  , 19.  , 28.  , 33.  , 17.  ,\n",
       "        27.  , 28.  , 22.  , 48.  , 28.  , 39.  , 36.  , 28.  , 40.  ,\n",
       "        28.  , 24.  , 19.  , 29.  , 32.  , 62.  , 53.  , 36.  , 16.  ,\n",
       "        34.  , 25.  , 36.  , 47.  , 60.  , 28.  , 35.  , 52.  , 47.  ,\n",
       "        28.  , 37.  , 36.  , 28.  , 49.  , 28.  , 49.  , 35.  , 36.  ,\n",
       "        30.  , 27.  , 22.  , 40.  , 39.  , 28.  , 28.  , 35.  , 24.  ,\n",
       "        34.  , 26.  , 20.  , 61.  , 57.  , 21.  , 26.  , 28.  , 80.  ,\n",
       "        51.  , 32.  ,  9.  , 28.  , 32.  , 41.  , 28.  , 20.  , 28.  ,\n",
       "         0.75, 48.  , 28.  , 23.  , 28.  , 18.  , 21.  , 24.  , 28.  ,\n",
       "        32.  , 50.  , 47.  , 36.  , 20.  , 25.  , 28.  , 43.  , 40.  ,\n",
       "        31.  , 31.  , 28.  , 18.  , 18.  , 36.  , 27.  , 20.  , 14.  ,\n",
       "        60.  , 19.  , 18.  , 15.  , 31.  ,  4.  , 28.  , 60.  , 28.  ,\n",
       "        49.  , 35.  , 25.  , 39.  , 22.  , 28.  , 24.  , 28.  , 48.  ,\n",
       "        29.  , 19.  , 38.  , 27.  , 28.  , 33.  ,  6.  , 50.  , 27.  ,\n",
       "        30.  , 25.  , 25.  , 29.  , 11.  , 28.  , 23.  , 23.  , 35.  ,\n",
       "        28.  , 28.  , 36.  , 21.  , 24.  , 70.  ,  4.  ,  6.  , 33.  ,\n",
       "        23.  , 48.  , 28.  , 34.  , 28.  , 41.  , 20.  , 51.  , 28.  ,\n",
       "        28.  , 32.  , 48.  , 57.  , 18.  , 28.  ,  5.  , 17.  , 29.  ,\n",
       "        28.  , 25.  ,  1.  , 46.  , 28.  , 16.  , 28.  , 28.  , 25.  ,\n",
       "        39.  , 49.  , 31.  , 30.  , 30.  , 34.  , 31.  , 11.  , 31.  ,\n",
       "        39.  , 39.  , 33.  , 26.  , 39.  , 35.  , 30.5 , 28.  , 23.  ,\n",
       "        31.  , 10.  , 52.  , 27.  ,  2.  , 28.  , 28.  , 28.  , 15.  ,\n",
       "        28.  , 23.  , 18.  , 39.  , 21.  , 28.  , 28.  , 16.  , 30.  ,\n",
       "        34.5 , 42.  , 28.  , 35.  , 28.  , 28.  ,  4.  , 16.  , 18.  ,\n",
       "        45.  , 51.  , 24.  , 41.  , 24.  , 42.  , 27.  , 31.  ,  4.  ,\n",
       "        26.  , 47.  , 33.  , 47.  , 28.  , 15.  , 20.  , 19.  , 28.  ,\n",
       "        22.  , 28.  , 25.  , 19.  , 28.  , 32.  ]),\n",
       " 'n_siblings_spouses': array([1, 1, 0, 1, 0, 3, 0, 1, 1, 0, 1, 0, 4, 0, 1, 0, 0, 0, 1, 0, 3, 0,\n",
       "        0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 2, 1, 4, 1, 1, 0, 0,\n",
       "        0, 0, 5, 0, 0, 1, 3, 1, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 3, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 4, 0, 0, 4, 1, 3, 0, 0, 0,\n",
       "        8, 0, 4, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 8, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 0, 1, 0, 0, 1, 8, 0, 0, 1, 2, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 5, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 2, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 1, 0, 5, 0, 0, 1, 3,\n",
       "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 4, 4, 1, 1, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 2, 1, 0,\n",
       "        0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 5, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 3, 1, 0, 4, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 8, 0, 0, 1, 4, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " 'parch': array([0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 5, 0, 1, 0, 0, 0, 0, 0, 5, 0, 2, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "        0, 3, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0,\n",
       "        0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "        2, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 2, 1, 0, 0, 1, 2, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 4, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 2, 3, 4, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 1, 1, 2, 0, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 1, 2,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 0,\n",
       "        2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 5, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1,\n",
       "        1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "        0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 2, 0, 1, 0, 2, 1, 1, 1, 0, 3, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]),\n",
       " 'fare': array([  7.25 ,  71.283,   7.925,  53.1  ,   8.458,  21.075,  11.133,\n",
       "         30.071,  16.7  ,   8.05 ,  31.275,   7.854,  29.125,  13.   ,\n",
       "         18.   ,   7.225,  26.   ,  35.5  ,  31.387,   7.225, 263.   ,\n",
       "          7.879,   7.896,  27.721, 146.521,   7.75 ,  10.5  ,  82.171,\n",
       "         52.   ,   7.229,  11.242,   9.475,  21.   ,   7.896,  41.579,\n",
       "          8.05 ,  15.5  ,  21.679,  17.8  ,  39.688,  76.729,  26.   ,\n",
       "         61.979,  35.5  ,  10.5  ,   7.229,  46.9  ,   7.229,  80.   ,\n",
       "         83.475,  27.9  ,  15.246,   8.158,   7.925,   8.662,  10.5  ,\n",
       "         73.5  ,  56.496,   7.65 ,   7.896,   8.05 ,  29.   ,  12.475,\n",
       "          9.   ,   9.5  ,   7.787,  47.1  ,  34.375,   8.05 , 263.   ,\n",
       "          8.05 ,  61.175,   7.25 ,   8.05 ,  34.654,  63.358,  23.   ,\n",
       "         26.   ,   7.896,   7.896,  77.287,   8.654,   7.925,   7.896,\n",
       "          7.775,  24.15 ,  52.   ,  14.454,   8.05 ,  14.458,   7.925,\n",
       "          7.75 ,  21.   , 247.521,   8.05 ,  30.071,  13.   ,   7.75 ,\n",
       "          7.142,   6.975,   7.05 ,  14.5  ,  15.046,  26.283,  53.1  ,\n",
       "          9.217,  79.2  ,  15.246,   7.75 ,   6.75 ,  11.5  ,  34.375,\n",
       "         12.525,   8.05 ,  14.5  ,   7.312,  61.379,   7.733,   8.662,\n",
       "         69.55 ,  16.1  ,   7.775,   8.662,  39.688,  55.   ,  56.496,\n",
       "         29.125,   7.854,  25.467,  28.712,  13.   ,   0.   ,  69.55 ,\n",
       "         15.05 ,  31.387,  22.025,  15.5  ,  26.55 ,   7.896,  13.   ,\n",
       "          7.854,  26.   ,  27.721, 146.521,   7.75 ,   7.75 ,  13.   ,\n",
       "          9.5  ,  69.55 ,   6.496,  10.463,  15.85 ,  18.788,   7.75 ,\n",
       "         31.   ,  21.   ,   7.25 ,   7.75 , 113.275,   7.925,  27.   ,\n",
       "         10.5  ,   8.05 ,   8.05 ,   9.35 ,  10.5  ,   7.25 ,  13.   ,\n",
       "         25.467,  83.475,   7.775,  13.5  ,   7.55 ,  26.   ,  10.5  ,\n",
       "         12.275,  14.454,  15.5  ,   7.125,   7.225,  90.   ,  14.5  ,\n",
       "          7.25 ,  10.463,  16.1  ,  20.212,  79.2  , 512.329,  26.   ,\n",
       "          7.75 ,  31.387,   0.   ,   7.75 ,  10.5  ,  39.688,   7.775,\n",
       "        153.463, 135.633,  31.   ,   0.   ,  19.5  ,  29.7  ,   7.75 ,\n",
       "         77.958,   7.75 ,   0.   ,  29.125,  20.25 ,   7.854,   9.5  ,\n",
       "         26.   ,  78.85 ,  12.875,   7.896,  30.5  , 247.521,   7.75 ,\n",
       "          0.   ,  12.35 ,   8.05 , 110.883, 108.9  ,  24.   ,  56.929,\n",
       "         83.158, 262.375,  26.   ,   7.896,  26.25 ,  26.   , 164.867,\n",
       "        134.5  ,   7.25 ,   7.896,  29.   ,  69.55 , 135.633,   6.237,\n",
       "         20.525,  23.25 , 153.463, 133.65 ,   7.896,  66.6  ,   8.05 ,\n",
       "         35.5  ,  13.   ,  13.   ,  13.   ,  13.   ,  13.   ,  16.1  ,\n",
       "          7.229,  17.8  ,   7.225,   9.5  ,  55.   ,  13.   ,   7.879,\n",
       "          7.879,  27.9  ,  27.721,  14.454,   7.05 ,  15.5  ,  75.25 ,\n",
       "          7.229,   7.75 ,  69.3  ,   6.496,   8.05 ,  82.171, 211.5  ,\n",
       "          7.775, 227.525,   7.925,   7.896,  73.5  ,  46.9  ,   7.729,\n",
       "         12.   , 120.   ,   7.796, 113.275,  16.7  ,   7.796,   7.854,\n",
       "         26.   ,  10.5  ,   7.925,   8.05 ,  15.85 ,  21.   ,  18.75 ,\n",
       "          7.775,  25.467,   7.896,   6.858,   0.   ,   7.925,   8.05 ,\n",
       "         32.5  ,  13.   ,  13.   ,   7.896,   7.733,  20.212,  26.   ,\n",
       "          7.75 ,   8.05 ,  26.55 ,  16.1  ,  26.   ,   7.125,  55.9  ,\n",
       "        120.   ,  18.75 , 263.   ,  10.5  ,  26.25 ,   9.5  ,  13.   ,\n",
       "          8.113,  26.55 ,  19.258,  30.5  ,  27.75 ,  27.75 ,  89.104,\n",
       "          7.896,  26.55 ,  51.862,  26.55 ,   8.05 ,  38.5  ,   8.05 ,\n",
       "          7.05 ,  26.55 ,   7.725,  19.258,   7.25 ,  27.75 ,  13.792,\n",
       "         52.   ,  21.   ,   7.046,  12.287,  46.9  ,   0.   ,   9.588,\n",
       "         91.079,  25.467,  90.   ,  29.7  ,  15.9  ,  19.967,  49.504,\n",
       "          8.05 , 151.55 ,   8.662,   7.75 ,   9.588, 108.9  ,  26.   ,\n",
       "         26.55 ,  56.496,  59.4  ,   7.496,  34.021,  10.5  ,  26.   ,\n",
       "          7.896,  93.5  ,   7.896,  57.979,   7.229,   7.75 ,  10.5  ,\n",
       "        221.779,  11.5  ,  26.   ,   7.229,  22.358,   8.662,  26.25 ,\n",
       "         26.55 , 106.425,  49.5  ,  71.   ,  31.275,  31.275, 106.425,\n",
       "         26.   ,  13.863,  20.525, 110.883,  26.   ,   7.829,   7.775,\n",
       "         39.6  , 227.525,  79.65 ,  17.4  ,   7.75 ,   7.896,   8.05 ,\n",
       "         24.15 ,   7.896,  21.075,   7.854,  10.5  ,  51.479,  26.387,\n",
       "          8.05 ,  13.   ,  30.   ,  40.125,  15.   ,  79.2  ,   8.05 ,\n",
       "          7.125,  78.267,   7.25 ,   7.75 ,  26.   ,  24.15 ,  33.   ,\n",
       "          0.   ,   7.225,  56.929,  26.55 ,  15.55 ,   7.896,  30.5  ,\n",
       "         41.579, 153.463,  31.275,   7.05 ,  15.5  ,   8.05 ,  65.   ,\n",
       "         14.4  ,  10.5  ,  15.742,  32.321,  12.35 ,  77.958,   7.896,\n",
       "          7.733,  30.   ,   7.054,  30.5  ,  27.9  ,  13.   ,   7.925,\n",
       "         39.688,  16.1  ,   7.854,  56.496,  19.258,  76.729,   7.55 ,\n",
       "          7.55 ,   7.896,  23.   ,   8.433,  73.5  ,   7.896,  15.5  ,\n",
       "        133.65 ,  25.587,   7.496,   7.925,  13.   ,   7.775,   8.05 ,\n",
       "         39.   ,  52.   ,  13.   ,   0.   ,   7.775,   9.842, 512.329,\n",
       "         76.729,   9.225,  46.9  ,  39.   ,  10.171,   7.796, 211.338,\n",
       "         57.   ,  13.417,  56.496,  26.55 ,   7.733, 110.883,  26.288,\n",
       "          7.742,  26.   , 151.55 ,  15.246,  49.504,  26.55 ,  52.   ,\n",
       "          9.483,   7.65 , 227.525,  10.5  ,  15.5  ,   7.775,  33.   ,\n",
       "         13.   ,  53.1  ,  21.   ,  26.   ,   7.925, 211.338,  18.788,\n",
       "          0.   ,  13.   ,  13.   , 512.329,   7.896,   7.896,  78.85 ,\n",
       "        262.375,  16.1  ,  71.   ,  23.   ,  12.475,   9.5  ,   7.896,\n",
       "         65.   ,   7.796,   8.05 ,  14.5  ,   7.125,   7.229,  77.958,\n",
       "         39.6  ,  24.15 ,   8.363,   7.854,  10.5  ,   7.75 ,   7.75 ,\n",
       "         12.475,  57.   ,  30.   ,  23.45 ,   7.05 ,  20.575,  79.2  ,\n",
       "          7.75 ,  26.   ,  69.55 ,  30.696,   7.896,  13.   ,  25.929,\n",
       "          8.683,   7.229,  24.15 ,  13.   ,  26.25 , 120.   ,   7.775,\n",
       "          0.   ,  13.   ,  53.1  ,   7.888,  24.15 ,  10.5  ,   8.05 ,\n",
       "          0.   ,   7.925,  37.004,  27.9  ,  93.5  ,   8.662,  39.688,\n",
       "          6.95 ,  56.496,   7.75 ,  14.454,   7.229,   7.854,   8.3  ,\n",
       "         83.158,   8.662,   8.05 ,  29.7  ,  10.5  ,  31.   ,   6.438,\n",
       "          7.55 ,  69.55 ,   7.896,  33.   ,  89.104,  31.275,  39.4  ,\n",
       "          9.35 , 164.867,  26.55 ,  19.258,  14.108,  13.   ,  13.   ,\n",
       "         13.858,  50.496,  11.133,   7.896,  52.554,   5.   ,   9.   ,\n",
       "         24.   ,   7.225,   9.846,   7.896,   7.896,  10.517,  10.5  ,\n",
       "          7.05 ,  30.   ,  23.45 ,   7.75 ]),\n",
       " 'class': array(['Third', 'First', 'Third', 'First', 'Third', 'Third', 'Third',\n",
       "        'Second', 'Third', 'Third', 'Third', 'Third', 'Third', 'Second',\n",
       "        'Third', 'Third', 'Second', 'First', 'Third', 'Third', 'First',\n",
       "        'Third', 'Third', 'First', 'First', 'Third', 'Second', 'First',\n",
       "        'First', 'Third', 'Third', 'Third', 'Second', 'Third', 'Second',\n",
       "        'Third', 'Third', 'Third', 'Third', 'Third', 'First', 'Second',\n",
       "        'First', 'First', 'Second', 'Third', 'Third', 'Third', 'First',\n",
       "        'First', 'Third', 'Third', 'Third', 'Third', 'Third', 'Second',\n",
       "        'Second', 'Third', 'Third', 'Third', 'Third', 'Second', 'Third',\n",
       "        'Third', 'Third', 'Third', 'First', 'Third', 'Third', 'First',\n",
       "        'Third', 'First', 'Third', 'Third', 'First', 'First', 'Second',\n",
       "        'Second', 'Third', 'Third', 'First', 'Third', 'Third', 'Third',\n",
       "        'Third', 'Third', 'First', 'Third', 'Third', 'Third', 'Third',\n",
       "        'Third', 'Second', 'First', 'Third', 'Second', 'Second', 'Third',\n",
       "        'Third', 'Third', 'Third', 'Third', 'Second', 'First', 'First',\n",
       "        'Third', 'First', 'Third', 'Third', 'Third', 'Second', 'Third',\n",
       "        'Second', 'Third', 'Third', 'Third', 'First', 'Third', 'Third',\n",
       "        'Third', 'Third', 'Third', 'Third', 'Third', 'First', 'Third',\n",
       "        'Third', 'Third', 'Third', 'First', 'Second', 'Third', 'Third',\n",
       "        'Second', 'Third', 'Third', 'Third', 'First', 'Third', 'Second',\n",
       "        'Third', 'Second', 'First', 'First', 'Third', 'Third', 'Second',\n",
       "        'Third', 'Third', 'Third', 'Third', 'Third', 'Third', 'Third',\n",
       "        'First', 'Second', 'Third', 'Third', 'First', 'Third', 'Second',\n",
       "        'Second', 'Third', 'Third', 'Third', 'Second', 'Third', 'Second',\n",
       "        'Third', 'First', 'Third', 'Second', 'Third', 'Second', 'Second',\n",
       "        'Second', 'Third', 'Third', 'Third', 'Third', 'First', 'Second',\n",
       "        'Third', 'Third', 'Third', 'Third', 'First', 'First', 'Second',\n",
       "        'Third', 'Third', 'First', 'Third', 'Second', 'Third', 'Third',\n",
       "        'First', 'First', 'First', 'Third', 'Second', 'First', 'Third',\n",
       "        'First', 'Third', 'Second', 'Third', 'Third', 'Third', 'Third',\n",
       "        'First', 'First', 'Second', 'Third', 'First', 'First', 'Third',\n",
       "        'Third', 'Second', 'Third', 'First', 'First', 'Second', 'First',\n",
       "        'First', 'First', 'Second', 'Third', 'Second', 'Second', 'First',\n",
       "        'First', 'Third', 'Third', 'Second', 'Third', 'First', 'Third',\n",
       "        'Third', 'Third', 'First', 'First', 'Third', 'First', 'Third',\n",
       "        'First', 'Second', 'Second', 'Second', 'Second', 'Second', 'Third',\n",
       "        'Third', 'Third', 'Third', 'Third', 'First', 'Second', 'Third',\n",
       "        'Third', 'Third', 'Second', 'Third', 'Third', 'Third', 'First',\n",
       "        'Third', 'Third', 'First', 'Third', 'Third', 'First', 'First',\n",
       "        'Third', 'First', 'Third', 'Third', 'Second', 'Third', 'Third',\n",
       "        'Second', 'First', 'Third', 'First', 'Third', 'Third', 'Third',\n",
       "        'Second', 'Second', 'Third', 'Third', 'Third', 'Second', 'Second',\n",
       "        'Third', 'Third', 'Third', 'Third', 'Second', 'Third', 'Third',\n",
       "        'Second', 'Second', 'Second', 'Third', 'Third', 'Third', 'Second',\n",
       "        'Third', 'Third', 'First', 'Third', 'Second', 'Third', 'First',\n",
       "        'First', 'Second', 'First', 'Second', 'Second', 'Third', 'Second',\n",
       "        'Third', 'First', 'Third', 'First', 'Second', 'First', 'First',\n",
       "        'Third', 'First', 'First', 'First', 'Third', 'First', 'Third',\n",
       "        'Third', 'First', 'Third', 'Third', 'Third', 'Second', 'Second',\n",
       "        'First', 'Second', 'Third', 'Third', 'Third', 'Second', 'Third',\n",
       "        'First', 'Third', 'First', 'First', 'Third', 'Third', 'First',\n",
       "        'Third', 'First', 'Third', 'Third', 'Third', 'First', 'Second',\n",
       "        'First', 'Third', 'First', 'Third', 'First', 'Second', 'Second',\n",
       "        'Third', 'First', 'Third', 'First', 'Third', 'Third', 'Second',\n",
       "        'First', 'Second', 'Second', 'Third', 'Third', 'Third', 'Second',\n",
       "        'First', 'First', 'First', 'First', 'Third', 'Third', 'First',\n",
       "        'Second', 'Second', 'Third', 'First', 'Second', 'Third', 'Third',\n",
       "        'First', 'First', 'First', 'Third', 'Third', 'Third', 'Third',\n",
       "        'Third', 'Third', 'Third', 'Third', 'Second', 'First', 'First',\n",
       "        'Third', 'Second', 'Second', 'First', 'Second', 'First', 'Third',\n",
       "        'Third', 'First', 'Third', 'Third', 'Second', 'Third', 'Second',\n",
       "        'Third', 'Third', 'First', 'First', 'Third', 'Third', 'First',\n",
       "        'Second', 'First', 'Third', 'Third', 'Third', 'Third', 'Second',\n",
       "        'Third', 'Second', 'Third', 'First', 'Second', 'First', 'Third',\n",
       "        'Third', 'First', 'Third', 'First', 'Third', 'Second', 'Third',\n",
       "        'Third', 'Third', 'Third', 'Third', 'Third', 'First', 'Third',\n",
       "        'Third', 'Third', 'Second', 'Third', 'Second', 'Third', 'Third',\n",
       "        'First', 'First', 'Third', 'Third', 'Second', 'Third', 'Third',\n",
       "        'Second', 'First', 'Second', 'Second', 'Third', 'Third', 'First',\n",
       "        'First', 'Third', 'Third', 'Second', 'Third', 'Third', 'First',\n",
       "        'First', 'Third', 'Third', 'First', 'Third', 'First', 'First',\n",
       "        'Third', 'Second', 'First', 'Third', 'First', 'First', 'First',\n",
       "        'Third', 'Third', 'First', 'Second', 'Third', 'Third', 'Second',\n",
       "        'Second', 'First', 'Second', 'Second', 'Third', 'First', 'Third',\n",
       "        'Second', 'Second', 'Second', 'First', 'Third', 'Third', 'First',\n",
       "        'First', 'Third', 'First', 'Second', 'Third', 'Third', 'Third',\n",
       "        'Second', 'Third', 'Third', 'Third', 'Third', 'Third', 'First',\n",
       "        'First', 'Third', 'Third', 'Third', 'Second', 'Third', 'Third',\n",
       "        'Third', 'First', 'First', 'Third', 'Third', 'Third', 'First',\n",
       "        'Third', 'Second', 'Third', 'First', 'Third', 'Second', 'First',\n",
       "        'Third', 'Third', 'Third', 'Second', 'Second', 'First', 'Third',\n",
       "        'First', 'Second', 'First', 'Third', 'Third', 'Second', 'Third',\n",
       "        'First', 'Third', 'Second', 'Third', 'First', 'Third', 'Third',\n",
       "        'Third', 'Third', 'Third', 'Third', 'Third', 'Third', 'Third',\n",
       "        'First', 'Third', 'Third', 'First', 'Second', 'First', 'Third',\n",
       "        'Third', 'Third', 'Third', 'Second', 'First', 'Third', 'First',\n",
       "        'Third', 'First', 'First', 'Third', 'Third', 'Second', 'Second',\n",
       "        'Second', 'First', 'Third', 'Third', 'First', 'First', 'Third',\n",
       "        'Second', 'Third', 'Third', 'Third', 'Third', 'Third', 'Second',\n",
       "        'Third', 'First', 'Third', 'Third'], dtype=object),\n",
       " 'deck': array(['unknown', 'C', 'unknown', 'C', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'G', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'A', 'unknown',\n",
       "        'unknown', 'C', 'unknown', 'unknown', 'unknown', 'B', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'D', 'unknown', 'B', 'C', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'B', 'C', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'F', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'C',\n",
       "        'unknown', 'E', 'unknown', 'unknown', 'A', 'D', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'D', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'C', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'B', 'unknown',\n",
       "        'unknown', 'E', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'D', 'C', 'unknown', 'B', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'E', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'C', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'F', 'B', 'B', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'G',\n",
       "        'unknown', 'unknown', 'unknown', 'A', 'unknown', 'unknown',\n",
       "        'unknown', 'D', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'C', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'C',\n",
       "        'unknown', 'unknown', 'G', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'B', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'C', 'C', 'unknown', 'unknown',\n",
       "        'unknown', 'C', 'unknown', 'D', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'A', 'unknown', 'D', 'unknown',\n",
       "        'C', 'B', 'unknown', 'unknown', 'E', 'unknown', 'unknown', 'C',\n",
       "        'unknown', 'E', 'C', 'B', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'C', 'E', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'C', 'unknown', 'unknown', 'unknown', 'C', 'unknown', 'unknown',\n",
       "        'C', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'F',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'E', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'D', 'unknown', 'unknown', 'B',\n",
       "        'unknown', 'unknown', 'unknown', 'C', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'B', 'unknown', 'D', 'G', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'E', 'C', 'unknown', 'unknown',\n",
       "        'unknown', 'E', 'B', 'unknown', 'C', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'C',\n",
       "        'unknown', 'C', 'C', 'unknown', 'E', 'D', 'E', 'unknown', 'E',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'D', 'A', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'B', 'unknown', 'C', 'B', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'C', 'unknown', 'unknown',\n",
       "        'unknown', 'C', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'D', 'F', 'unknown', 'unknown', 'B', 'unknown', 'B',\n",
       "        'unknown', 'unknown', 'unknown', 'C', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'B', 'unknown', 'B',\n",
       "        'B', 'unknown', 'unknown', 'C', 'unknown', 'unknown', 'unknown',\n",
       "        'C', 'unknown', 'unknown', 'unknown', 'A', 'unknown', 'E',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'C', 'E', 'unknown', 'unknown',\n",
       "        'unknown', 'A', 'unknown', 'B', 'unknown', 'unknown', 'D',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'A', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'C', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'D', 'unknown', 'D',\n",
       "        'unknown', 'unknown', 'A', 'unknown', 'B', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'D', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'E', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'B',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'B', 'D', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'B', 'B', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'C', 'E', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'C', 'C', 'C', 'unknown', 'F', 'C', 'E',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'E', 'unknown',\n",
       "        'unknown', 'unknown', 'B', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'B', 'unknown', 'unknown', 'C', 'B', 'unknown', 'B',\n",
       "        'unknown', 'E', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'D', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'E', 'unknown', 'F', 'unknown',\n",
       "        'B', 'D', 'unknown', 'unknown', 'unknown', 'B', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'D',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'B',\n",
       "        'unknown', 'A', 'unknown', 'E', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'B', 'unknown', 'unknown', 'unknown', 'B', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'E', 'unknown', 'unknown', 'C', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'C', 'unknown', 'D', 'unknown', 'unknown', 'E', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'A', 'unknown',\n",
       "        'unknown', 'D', 'B', 'unknown', 'unknown', 'unknown', 'unknown',\n",
       "        'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'B',\n",
       "        'unknown', 'unknown'], dtype=object),\n",
       " 'embark_town': array(['Southampton', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Queenstown', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Queenstown', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Queenstown', 'Southampton', 'Cherbourg',\n",
       "        'Cherbourg', 'Queenstown', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Cherbourg', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Cherbourg', 'Southampton',\n",
       "        'Queenstown', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Southampton', 'Cherbourg', 'unknown',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Queenstown', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Queenstown', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Queenstown', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Queenstown', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Cherbourg', 'Southampton',\n",
       "        'Queenstown', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Queenstown', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Queenstown', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Southampton', 'Queenstown',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Cherbourg', 'Queenstown',\n",
       "        'Queenstown', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Queenstown', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Queenstown', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Queenstown', 'Southampton', 'Cherbourg', 'Queenstown',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Cherbourg', 'Southampton',\n",
       "        'Queenstown', 'Southampton', 'Southampton', 'Queenstown',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Queenstown', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Queenstown', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Queenstown',\n",
       "        'Southampton', 'Queenstown', 'Southampton', 'Cherbourg',\n",
       "        'Cherbourg', 'Cherbourg', 'Cherbourg', 'Cherbourg', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Queenstown', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Queenstown', 'Queenstown', 'Southampton', 'Cherbourg',\n",
       "        'Cherbourg', 'Southampton', 'Queenstown', 'Cherbourg', 'Cherbourg',\n",
       "        'Queenstown', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Cherbourg', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Queenstown', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Queenstown', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Queenstown', 'Southampton',\n",
       "        'Southampton', 'Queenstown', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Cherbourg', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Queenstown',\n",
       "        'Cherbourg', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Queenstown', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Cherbourg', 'Queenstown', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Cherbourg', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Queenstown', 'Southampton',\n",
       "        'Cherbourg', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Queenstown', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Queenstown', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Cherbourg', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Queenstown',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Queenstown', 'Southampton',\n",
       "        'Southampton', 'Queenstown', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Queenstown', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Cherbourg', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Southampton', 'Queenstown',\n",
       "        'Cherbourg', 'Southampton', 'Queenstown', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Cherbourg',\n",
       "        'Southampton', 'Queenstown', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Cherbourg', 'Queenstown', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Queenstown', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Queenstown', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Queenstown', 'Southampton',\n",
       "        'Queenstown', 'Cherbourg', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Southampton', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Cherbourg', 'Cherbourg',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Cherbourg', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Cherbourg', 'Cherbourg', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Southampton',\n",
       "        'Southampton', 'Southampton', 'Southampton', 'Queenstown'],\n",
       "       dtype=object),\n",
       " 'alone': array(['n', 'n', 'y', 'n', 'y', 'n', 'n', 'n', 'n', 'y', 'n', 'y', 'n',\n",
       "        'y', 'n', 'y', 'y', 'y', 'n', 'y', 'n', 'y', 'y', 'y', 'n', 'y',\n",
       "        'y', 'n', 'n', 'y', 'n', 'n', 'n', 'y', 'n', 'y', 'n', 'n', 'n',\n",
       "        'n', 'n', 'n', 'n', 'y', 'y', 'y', 'n', 'y', 'y', 'n', 'n', 'n',\n",
       "        'y', 'n', 'n', 'y', 'y', 'y', 'y', 'y', 'y', 'n', 'y', 'y', 'y',\n",
       "        'y', 'y', 'n', 'y', 'n', 'y', 'n', 'y', 'y', 'y', 'n', 'n', 'n',\n",
       "        'y', 'y', 'n', 'y', 'n', 'y', 'y', 'n', 'y', 'n', 'y', 'y', 'y',\n",
       "        'y', 'n', 'n', 'y', 'n', 'y', 'y', 'y', 'y', 'y', 'n', 'y', 'n',\n",
       "        'n', 'y', 'y', 'n', 'y', 'y', 'y', 'n', 'y', 'y', 'n', 'y', 'n',\n",
       "        'y', 'y', 'n', 'n', 'y', 'y', 'n', 'n', 'y', 'n', 'n', 'n', 'y',\n",
       "        'y', 'y', 'n', 'y', 'n', 'n', 'n', 'y', 'y', 'y', 'n', 'n', 'y',\n",
       "        'y', 'y', 'y', 'y', 'y', 'n', 'y', 'n', 'n', 'y', 'y', 'y', 'y',\n",
       "        'y', 'n', 'n', 'y', 'n', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'n',\n",
       "        'n', 'y', 'y', 'y', 'n', 'y', 'y', 'n', 'n', 'y', 'y', 'n', 'n',\n",
       "        'y', 'n', 'n', 'n', 'y', 'y', 'n', 'y', 'n', 'y', 'y', 'y', 'n',\n",
       "        'n', 'n', 'y', 'y', 'y', 'n', 'n', 'y', 'n', 'y', 'y', 'n', 'n',\n",
       "        'y', 'y', 'y', 'y', 'y', 'y', 'y', 'n', 'y', 'y', 'y', 'y', 'y',\n",
       "        'n', 'n', 'y', 'y', 'n', 'n', 'y', 'n', 'n', 'n', 'n', 'y', 'y',\n",
       "        'n', 'n', 'y', 'y', 'n', 'n', 'n', 'n', 'y', 'n', 'y', 'y', 'y',\n",
       "        'y', 'y', 'y', 'y', 'n', 'n', 'n', 'y', 'y', 'n', 'y', 'y', 'y',\n",
       "        'n', 'n', 'n', 'y', 'n', 'n', 'y', 'y', 'y', 'n', 'y', 'n', 'n',\n",
       "        'y', 'y', 'y', 'y', 'y', 'n', 'y', 'y', 'n', 'y', 'n', 'n', 'y',\n",
       "        'y', 'y', 'y', 'y', 'y', 'n', 'n', 'n', 'y', 'n', 'y', 'y', 'y',\n",
       "        'y', 'y', 'n', 'n', 'y', 'y', 'y', 'n', 'y', 'y', 'y', 'y', 'n',\n",
       "        'n', 'y', 'n', 'n', 'n', 'n', 'y', 'n', 'y', 'y', 'y', 'y', 'n',\n",
       "        'y', 'n', 'y', 'n', 'y', 'y', 'n', 'y', 'y', 'y', 'y', 'y', 'y',\n",
       "        'y', 'n', 'y', 'n', 'y', 'y', 'n', 'n', 'n', 'n', 'y', 'y', 'n',\n",
       "        'n', 'n', 'y', 'n', 'n', 'y', 'y', 'n', 'y', 'y', 'y', 'n', 'n',\n",
       "        'y', 'y', 'n', 'y', 'y', 'y', 'n', 'y', 'y', 'y', 'n', 'y', 'y',\n",
       "        'y', 'y', 'n', 'n', 'n', 'n', 'y', 'n', 'y', 'y', 'n', 'n', 'n',\n",
       "        'n', 'n', 'n', 'y', 'n', 'n', 'y', 'y', 'y', 'n', 'y', 'n', 'n',\n",
       "        'y', 'y', 'y', 'n', 'y', 'n', 'y', 'y', 'n', 'y', 'y', 'y', 'n',\n",
       "        'y', 'y', 'n', 'y', 'y', 'n', 'y', 'n', 'n', 'n', 'y', 'y', 'y',\n",
       "        'n', 'y', 'n', 'y', 'y', 'n', 'y', 'n', 'y', 'n', 'y', 'n', 'n',\n",
       "        'y', 'n', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'n', 'y', 'y',\n",
       "        'n', 'n', 'y', 'y', 'n', 'n', 'y', 'y', 'y', 'n', 'y', 'n', 'y',\n",
       "        'n', 'n', 'y', 'y', 'n', 'y', 'y', 'y', 'n', 'n', 'y', 'y', 'y',\n",
       "        'y', 'n', 'y', 'y', 'n', 'n', 'y', 'y', 'n', 'n', 'n', 'y', 'y',\n",
       "        'y', 'n', 'y', 'y', 'y', 'y', 'n', 'y', 'y', 'n', 'y', 'y', 'y',\n",
       "        'y', 'y', 'y', 'n', 'y', 'n', 'n', 'n', 'n', 'y', 'y', 'y', 'y',\n",
       "        'y', 'y', 'y', 'y', 'n', 'n', 'n', 'n', 'n', 'n', 'y', 'y', 'n',\n",
       "        'y', 'y', 'y', 'y', 'y', 'n', 'y', 'n', 'y', 'y', 'y', 'y', 'y',\n",
       "        'y', 'n', 'y', 'n', 'y', 'n', 'y', 'y', 'y', 'n', 'y', 'y', 'y',\n",
       "        'y', 'y', 'y', 'n', 'y', 'n', 'n', 'y', 'y', 'y', 'n', 'y', 'y',\n",
       "        'y', 'y', 'y', 'y', 'n', 'n', 'n', 'y', 'n', 'y', 'y', 'y', 'n',\n",
       "        'y', 'y', 'y', 'n', 'y', 'y', 'y', 'y', 'y', 'y', 'y', 'n', 'y',\n",
       "        'n', 'n', 'n', 'n', 'n', 'n', 'y', 'n', 'n', 'y', 'y', 'n', 'y',\n",
       "        'n', 'y', 'n', 'y', 'y', 'n', 'y', 'y', 'y', 'y', 'y', 'y', 'y',\n",
       "        'y', 'n', 'y'], dtype=object)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "617e877c-32be-4c3b-8e38-5b35f44cab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a969e21-7a12-48b4-bec6-59031a1616d3",
   "metadata": {},
   "source": [
    "To train a model using this `Dataset`, you'll need to at least `shuffle` and `batch` the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2acd9020-3ace-4203-8eb5-b72977b28b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314cb852-5bda-4478-9398-bd2706b1e5cc",
   "metadata": {},
   "source": [
    "Instead of passing `features` and `labels` to `Model.fit`, you pass the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "315f6c56-8606-4a26-b521-baad9469d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3998  \n",
      "Epoch 2/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3978\n",
      "Epoch 3/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4078\n",
      "Epoch 4/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4176\n",
      "Epoch 5/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x795f647d29d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(titanic_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bbbefc-43fa-4d75-a37e-59ac85279a74",
   "metadata": {},
   "source": [
    "### From a single file\n",
    "So far this tutorial has worked with in-memory data. `tf.data` is a highly scalable toolkit for building data pipelines, and provides a few functions for loading CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c1779e1-9c34-4d8d-a158-660becd994c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "\u001b[1m30874/30874\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409a5df-ead7-4e7a-a7b2-42a67d443cfb",
   "metadata": {},
   "source": [
    "**`tf.data.experimental.make_csv_dataset`**  \n",
    "\n",
    "Now read the CSV data from the file and create a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset).\n",
    "\n",
    "(For the full documentation, see [`tf.data.experimental.make_csv_dataset`](https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cf7ce2a-d13b-43bc-a771-ae388519e101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/ops/readers.py:572: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ignore_errors` instead.\n"
     ]
    }
   ],
   "source": [
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file_path,\n",
    "    batch_size=5, # Artificially small to make examples easier to show.\n",
    "    label_name='survived',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ec819b-db20-484c-80f5-bacdae79ecf8",
   "metadata": {},
   "source": [
    "This function includes many convenient features, so the data is easy to work with. This includes:\n",
    "\n",
    "- Using the column headers as dictionary keys.\n",
    "- Automatically determining the type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03c30700-79e9-4dfc-bdda-26ac0f9a8230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'male' b'male' b'male' b'female' b'female']\n",
      "age                 : [31. 36. 28. 57. 48.]\n",
      "n_siblings_spouses  : [1 0 0 0 1]\n",
      "parch               : [0 0 0 0 2]\n",
      "fare                : [52.    12.875  8.113 10.5   65.   ]\n",
      "class               : [b'First' b'Second' b'Third' b'Second' b'Second']\n",
      "deck                : [b'B' b'D' b'unknown' b'E' b'unknown']\n",
      "embark_town         : [b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Southampton']\n",
      "alone               : [b'n' b'y' b'y' b'y' b'n']\n",
      "\n",
      "label               : [0 0 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 01:13:38.891008: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch, label in titanic_csv_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8163f58-a2f7-4080-93ca-d35836f41be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
